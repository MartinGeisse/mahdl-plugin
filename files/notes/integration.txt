
How is MaHDL integrated with the remaining world? What *is* the remaining world?

Synthesis of full MaHDL design:
- takes additional info in additional files (like Xilinx "constraints" which are far more than just that)
- BUT: Limited by the language in some aspects, e.g. no bidir support
- unclear if useful (yes: developer need not know Java)

Synthesis of MaHDL design embedded in ESDK:
- code, not contraints file, provides all configuration
- limitation of MaHDL model is not a problem because the missing parts can be build using ESDK
- disadvantage: developer must be able to write Java

Simulation of full MaHDL design:
- testbench must be build using another language (if not Java code, then some testbench language)

Simulation of MaHDL design embedded in ESDK:
- this is the main topic, see below

---------------------------------------------------------------------------------------------------------------------
Simulation of MaHDL design embedded in ESDK

Variants:

- MaHDL compiler as part of the MaHDL plugin
    - compiles to Java?
    - compilation will cause additional error message because only then does the Java file change
    - the compiler output is hard to keep out of version control, and be checking in, a missing plugin won't be
        recognized because the old file will be used, causing followup problems
        - can be solved by generating to a separate source path
        - IntelliJ may have a solution for this, because the problem exists for all Java-generating DSLs
    - in an advanced stage, may be able to fully integrate with Java tooling to use ESDK library modules in MaHDL

- MaHDL compiler as ESDK library component
    - sub-variant: MaHDL plugin can generate a wrapper class
    - even in an advanced stage, ESDK library modules will never be integrated automatically into tooling
        - would need MaHDL-side stubs similar to "native" keyword in Java
        - that's not really a big problem; also, it only affects MaHDL module instances, not interfaces

- mix: MaHDL compiler as part of the plugin, but compiles to binary, not Java
    - no .gitignore problem
    - full Java integration possible in one direction
    - generating a Java wrapper class would need to be done manually

----------------

What are the goals? Especially, is "developer does not need to know Java" valuable?
- not for me personally
- a team would need Java devs anyway for simulation -- not having them at all is not a supported use case
- the team would need to work together -- dysfunctional teams are not a supported use case
- the pure HDL devs would then mostly keep off the Java parts
--> making Java a requirement is not a problem

The most useful variant therefore seems to pre-compile to Java as part of the IntelliJ build process.

----------------

Another variant:
- MaHDL source is separate from Java source
- Java components must be represented in MaHDL as stubs (but: interfaces are such a thing anyway)
- needs manual wiring on the Java side unless it is still a MaHDL-to-Java pre-compiler.
--> not a good variant. The idea is to *reduce* manual wiring!

Reduced manual wiring requires either reflection or code generation.
- code generation would happen in the MaHDL compiler. This happens when MaHDL is pre-compiled before running the
    Java compiler, as described above.
- reflection requires to make the Java side conform to MaHDL-defined coding styles -- the MaHDL compiler or runtime
    system would need to analyze the *surrounding* objects, whereas code generation would generate Java code that
    is agnostic to the surrounding objects.
- reflection also can't handle MaHDL interfaces well, only submodules.

So a MaHDL pre-compiler with Java code generation seems like the best solution. Interfaces are turned to signal
getters (OUT) and setters (IN); interface types are turned to helper objects with getters (OUT) and setters (IN),
best represented by a Java interface (instead of a helper object class) to disallow access to the internal counter-side
getters and setters, making the usage of it much clearer.

Submodules are an interesting part, and there are two types:
- submodule is Java:
    - Compiled Java may not exist at the time of MaHDL compilation (since MaHDL is compiled first), and analyzing the
        compiled Java is tricky but may work if one could get it. Analyzing the Java code structure is more likely to
        happen. Still, things like vector widths must be specified through annotations.
    - Alternatively, the Java object may be represented by a MaHDL stub ("native module"). MaHDL sources could be
        separate from Java then, and produce outputs in a "generated" Java source path as a pre-compiler.
        - In v1, the stub need not even be checked against the Java code by the pre-compiler. Any errors turn up in
            the generated Java code or at runtime -- both are ugly, but hardly a show stopper since they crash
            immediately and are easy to track down.
- submodule is MaHDL
    - Easy for the compiler to analyze MaHDL. Might also be able to analyze the compiled code (interface definition
        files generated in addition to Java) to improve performance.
    - There is no reason to analyze the Java code, especially when Java-only modules use a MaHDL stub.

----------------

Implementation variants:
- IntelliJ builder module -- requires using IntelliJ for building
    - faster
    - cannot work without IntelliJ
- Gradle Plugin -- requires using gradle for building
    - slower
    - could use another IDE or simple editor
    - runs in CI, e.g. Jenkins

--->
I accidentally used an old Gradle version via Wrapper. The new gradle is pretty fast, so writing a Gradle plugin
seems to have only advantages over an IntelliJ builder.


---------------------------------------------------------------------------------------------------------------------

Next steps:

1. Refactoring
- consider removing the "processing" from IntelliJ (possible if it *can* be abstracted from the PSI *and* the
    IntelliJ annotator does not need too much processing)
- convert project into three projects in the same git repo: common processing steps, IntelliJ plugin, Gradle plugin
    (or two if no common code can be extracted)
- move codegen to Gradle plugin; move functions to either Gradle plugin or common code

2. Gradle Plugin
- integrate into Gradle
- get a full build process working in IntelliJ with both plugins, including visible build error messages

3. Change code generation to target ESDK, not Verilog directly



